{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMdc5UHrf5hxLjt4qTd+Vff",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nnennandukwe/GenAI-Dev-Onboarding-Starter-Kit/blob/main/GenAI_Dev_Onboarding_Starter_Kit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gen AI Dev Onboarding Starter Kit #1: Intro to RAG! ðŸš€\n",
        "\n",
        "Welcome! This notebook guides you through a Retrieval Augmented Generation (RAG) pipeline demonstration, built for developers (or enthusiasts) looking to get started in hands-on Generative AI!\n",
        "\n",
        "### Tools You'll Use\n",
        "\n",
        "- LangChain\n",
        "- OpenAI\n",
        "- ChromaDB\n",
        "- Ragas\n",
        "\n",
        "\n",
        "### Key steps covered:\n",
        "1.  Setting up the environment and installing dependencies (including Langchain).\n",
        "2.  Processing local documents (`doc1.txt` - Security Guidelines, `doc2.txt` - Company FAQs) using Langchain document loaders and text splitters.\n",
        "3.  Generating embeddings using Langchain wrappers for OpenAI (`text-embedding-3-small`).\n",
        "4.  Storing and indexing embeddings in ChromaDB using Langchain integration.\n",
        "5.  Performing Question Answering using a Langchain `RetrievalQA` chain.\n",
        "6.  Evaluating the RAG pipeline using Ragas (metrics: context precision, context recall, faithfulness), leveraging Langchain components.\n",
        "\n",
        "### Before you begin\n",
        "\n",
        "*   You will need an OpenAI API key.\n",
        "*   The project files (including `embedding_processor_langchain.py`, `evaluation_langchain.py`, `doc1.txt`, `doc2.txt`, and `pyproject.toml`) should be accessible in your Colab environment (e.g., by cloning a Git repository or uploading them) once you've run Step 1 in order to complete the guide!"
      ],
      "metadata": {
        "id": "bfuQY6wsIb8H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Setup Environment"
      ],
      "metadata": {
        "id": "0QdDs7fuD_0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the project repository if not already done\n",
        "!git clone https://github.com/nnennandukwe/GenAI-Dev-Onboarding-Starter-Kit.git\n",
        "\n",
        "# Change directory to the project folder\n",
        "%cd GenAI-Dev-Onboarding-Starter-Kit\n",
        "\n",
        "print(\"Environment setup started...\")"
      ],
      "metadata": {
        "id": "Sjs0dOI2MBI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm you're in the correct directory before we begin installation\n",
        "import os\n",
        "project_root = os.getcwd()\n",
        "print(project_root) # output below should be /content/GenAI-Dev-Onboarding-Starter-Kit/"
      ],
      "metadata": {
        "collapsed": true,
        "id": "L9Nb1Q5qY88l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Poetry for managing Python dependencies"
      ],
      "metadata": {
        "id": "kYRmKw91Ln86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Poetry\n",
        "!curl -sSL https://install.python-poetry.org | python3 -\n",
        "\n",
        "# Add Poetry to PATH for the current Colab session\n",
        "import os\n",
        "os.environ[\"PATH\"] += \":\" + os.path.expanduser(\"~/.local/bin\")\n",
        "\n",
        "!poetry --version\n",
        "print(\"Poetry installed.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OvpGL34KMFvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install project dependencies with Poetry"
      ],
      "metadata": {
        "id": "Bgw20FvfLhcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This command reads pyproject.toml and installs all dependencies including Langchain.\n",
        "!poetry install --no-root\n",
        "print(\"Project dependencies (including Langchain) installed.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ktNy6nL5OAHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up OpenAI API Key"
      ],
      "metadata": {
        "id": "m9K33y__L0b2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from getpass import getpass\n",
        "\n",
        "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "colab_api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "if not api_key:\n",
        "\n",
        "  if colab_api_key:\n",
        "    api_key = colab_api_key\n",
        "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "    print(\"Using Google Colab API key.\")\n",
        "  # Check for Google Colab key\n",
        "  else:\n",
        "    # Request for new OpenAI API key if none available\n",
        "    api_key = getpass(\"Please enter your OpenAI API key: \")\n",
        "\n",
        "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "    colab_api_key = api_key\n",
        "\n",
        "if os.environ.get(\"OPENAI_API_KEY\") or colab_api_key:\n",
        "    print(\"OpenAI API key set successfully!\")\n",
        "else:\n",
        "    print(\"Failed to set OpenAI API key.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DRsudSN4Ohz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Data Processing and Embedding (Langchain)"
      ],
      "metadata": {
        "id": "Of_7mWDRIBin"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will use the **Langchain-based script** (`embedding_processor_langchain.py`) to:\n",
        "1. Load documents (`doc1.txt`, `doc2.txt`) using `TextLoader`.\n",
        "2. Split documents into chunks using `RecursiveCharacterTextSplitter`.\n",
        "3. Generate embeddings with `OpenAIEmbeddings` (`text-embedding-3-small`).\n",
        "4. Store chunks and embeddings in ChromaDB via its Langchain integration.\n",
        "\n",
        "> Make sure `doc1.txt`, `doc2.txt`, and `embedding_processor_langchain.py` (inside the `my_rag_project` subdirectory) are present."
      ],
      "metadata": {
        "id": "HE7EkT-DTBaP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Double-check current directory and available script files"
      ],
      "metadata": {
        "id": "Fh9o8vkxMHbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "project_root = os.getcwd() # Should be /content/GenAI-Dev-Onboarding-Starter-Kit\n",
        "script_dir = os.path.join(project_root, \"my_rag_project\") # where scripts go\n",
        "\n",
        "!ls -l {project_root}\n",
        "!ls -l {script_dir}"
      ],
      "metadata": {
        "collapsed": true,
        "id": "deolCjS5TJzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the Langchain embedding processor script"
      ],
      "metadata": {
        "id": "01oqxbV-MVVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This script will use Langchain for loading, chunking, embedding, and storing in ChromaDB.\n",
        "# Ensure your OPENAI_API_KEY is set.\n",
        "\n",
        "!poetry run python my_rag_project/embedding_processor_langchain.py\n",
        "\n",
        "print(\"Langchain embedding process execution attempted.\")\n",
        "# Check for the new chroma_db_langchain directory\n",
        "!ls -l\n",
        "!ls -l chroma_db_langchain # This should exist if the script ran successfully"
      ],
      "metadata": {
        "collapsed": true,
        "id": "JRG3IScIT2ZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Ragas Evaluation (Langchain Pipeline)"
      ],
      "metadata": {
        "id": "6APArGppIND5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll use the **Langchain-based Ragas evaluation script** (`evaluation_langchain.py`). This script will:\n",
        "1.  Connect to the ChromaDB populated by the Langchain embedding script.\n",
        "2.  Set up a Langchain `RetrievalQA` chain using an OpenAI LLM (`gpt-3.5-turbo` or similar) and the ChromaDB retriever.\n",
        "3.  Generate answers for predefined questions using the QA chain.\n",
        "4.  Retrieve contexts (source documents) used by the QA chain.\n",
        "5.  Calculate Ragas metrics: `context_precision`, `context_recall`, and `faithfulness`.\n",
        "\n",
        "> Make sure `evaluation_langchain.py` (inside `my_rag_project` subdirectory) is present."
      ],
      "metadata": {
        "id": "ktlniz7v0r0T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the Langchain Ragas evaluation script"
      ],
      "metadata": {
        "id": "-Sg9f_4KLRH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This script requires the ChromaDB (langchain version) to be populated.\n",
        "# It also requires the OPENAI_API_KEY.\n",
        "!poetry run python my_rag_project/evaluation_langchain.py\n",
        "\n",
        "print(\"Langchain Ragas evaluation process execution attempted.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "sDBUKzPd09tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Conclusion: You Did it! ðŸŽŠ âœ…\n",
        "\n",
        "This notebook demonstrated the core steps of setting up a RAG pipeline **using Langchain**, from document processing and embedding to QA and evaluation with Ragas.\n",
        "\n",
        "**Further exploration:**\n",
        "*   Explore the `embedding_processor_langchain.py` and `evaluation_langchain.py` files to get a deeper look into the embedding and evaluation code!\n",
        "*   Try different LLMs available through Langchain. (all you have to do is edit the name of the model `LLM_MODEL` value in `evaluation_langchain.py` file!)\n",
        "*   Explore more advanced Langchain chains and agents for RAG.\n",
        "*   Expand the evaluation dataset and [other Ragas metrics](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/) in conjunction with Langchain."
      ],
      "metadata": {
        "id": "0UWWCWaYISp6"
      }
    }
  ]
}